{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jeffsan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/jeffsan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jeffsan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# download necessary NLTK data\n",
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet', 'stopwords'])\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords \n",
    "import re\n",
    "\n",
    "#sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, HashingVectorizer\n",
    "from sklearn.pipeline import Pipeline,  FeatureUnion\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///DisasterResponse.db')\n",
    "df = pd.read_sql(\"SELECT * FROM messages\", engine)\n",
    "X = df[['message', 'genre']]\n",
    "Y = df.drop(columns=['id', 'message', 'original','genre'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    #remove punctuation\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    \n",
    "    #tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # initiate lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    #iterate for each tokens\n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        \n",
    "        if tok not in stopwords.words('english'):\n",
    "            # lemmatize, normalize case, and remove leading/trailing white space\n",
    "            clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "\n",
    "            clean_tokens.append(clean_tok)\n",
    "    \n",
    "    return clean_tokens\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "- You'll find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "def get_msg(df):\n",
    "    return df['message']\n",
    "\n",
    "def get_genre_onehot(df):\n",
    "    return pd.get_dummies(df['genre'])\n",
    "\n",
    "# get_msg_data = FunctionTransformer(lambda x: x['message'], validate=False)\n",
    "# get_genre_data = FunctionTransformer(lambda x: pd.get_dummies(x['genre']), validate=False)\n",
    "\n",
    "get_msg_data = FunctionTransformer(get_msg, validate=False)\n",
    "get_genre_data = FunctionTransformer(get_genre_onehot, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_pipeline = Pipeline([\n",
    "    ('msg_selector', get_msg_data),\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "])\n",
    "\n",
    "features_pipeline_union = FeatureUnion([\n",
    "    ('msg_pipeline', msg_pipeline),\n",
    "    ('genre_pipeline', get_genre_data)\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features', features_pipeline_union),\n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier(random_state=42, n_jobs=-1), n_jobs=-1))\n",
    "    #('clf', OneVsRestClassifier(LogisticRegression(random_state=42), n_jobs=-1))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = tts(X,Y,test_size=0.33, random_state= 42)\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall on both the training set and the test set. You can use sklearn's `classification_report` function here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_report(model, X,y):\n",
    "    \"\"\" Print out classification report \"\"\"\n",
    "    y_pred = model.predict(X)\n",
    "    labels = y.columns.tolist()\n",
    "    class_report = classification_report(y, y_pred, target_names=labels)\n",
    "    print(\"\\nClassification report:\\n\", class_report)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "               related       0.88      0.97      0.92     13334\n",
      "               request       0.87      0.61      0.72      2980\n",
      "                 offer       0.00      0.00      0.00        82\n",
      "           aid_related       0.86      0.74      0.80      7277\n",
      "          medical_help       0.82      0.19      0.31      1391\n",
      "      medical_products       0.88      0.19      0.32       906\n",
      "     search_and_rescue       0.97      0.07      0.14       499\n",
      "              security       0.00      0.00      0.00       324\n",
      "              military       0.89      0.17      0.28       593\n",
      "           child_alone       0.00      0.00      0.00         0\n",
      "                 water       0.86      0.54      0.67      1155\n",
      "                  food       0.87      0.62      0.73      1949\n",
      "               shelter       0.87      0.44      0.58      1510\n",
      "              clothing       0.83      0.21      0.33       283\n",
      "                 money       0.93      0.07      0.14       382\n",
      "        missing_people       0.00      0.00      0.00       194\n",
      "              refugees       0.89      0.08      0.15       580\n",
      "                 death       0.94      0.30      0.45       804\n",
      "             other_aid       0.80      0.14      0.24      2284\n",
      "infrastructure_related       0.88      0.04      0.08      1129\n",
      "             transport       0.90      0.14      0.24       801\n",
      "             buildings       0.86      0.23      0.36       863\n",
      "           electricity       0.89      0.11      0.19       359\n",
      "                 tools       0.00      0.00      0.00       101\n",
      "             hospitals       1.00      0.02      0.03       197\n",
      "                 shops       0.00      0.00      0.00        81\n",
      "           aid_centers       0.00      0.00      0.00       180\n",
      "  other_infrastructure       0.75      0.02      0.04       773\n",
      "       weather_related       0.91      0.72      0.80      4856\n",
      "                floods       0.96      0.45      0.61      1448\n",
      "                 storm       0.87      0.53      0.66      1603\n",
      "                  fire       0.90      0.05      0.09       195\n",
      "            earthquake       0.92      0.67      0.77      1638\n",
      "                  cold       0.89      0.13      0.23       357\n",
      "         other_weather       0.93      0.05      0.09       901\n",
      "         direct_report       0.85      0.52      0.64      3391\n",
      "\n",
      "           avg / total       0.86      0.58      0.64     55400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeffsan/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jeffsan/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" LR on Train \"\"\"\n",
    "show_report(pipeline, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "               related       0.84      0.95      0.89      6542\n",
      "               request       0.82      0.56      0.67      1484\n",
      "                 offer       0.00      0.00      0.00        36\n",
      "           aid_related       0.77      0.67      0.72      3564\n",
      "          medical_help       0.60      0.14      0.23       690\n",
      "      medical_products       0.79      0.18      0.29       405\n",
      "     search_and_rescue       0.73      0.05      0.09       225\n",
      "              security       0.00      0.00      0.00       147\n",
      "              military       0.57      0.10      0.17       266\n",
      "           child_alone       0.00      0.00      0.00         0\n",
      "                 water       0.79      0.47      0.59       514\n",
      "                  food       0.86      0.57      0.69       968\n",
      "               shelter       0.85      0.40      0.54       798\n",
      "              clothing       0.85      0.19      0.31       121\n",
      "                 money       0.69      0.05      0.09       221\n",
      "        missing_people       1.00      0.01      0.02       104\n",
      "              refugees       0.71      0.04      0.08       294\n",
      "                 death       0.89      0.22      0.35       388\n",
      "             other_aid       0.65      0.10      0.18      1157\n",
      "infrastructure_related       0.50      0.02      0.04       576\n",
      "             transport       0.81      0.11      0.19       398\n",
      "             buildings       0.85      0.18      0.29       468\n",
      "           electricity       0.61      0.11      0.19       173\n",
      "                 tools       0.00      0.00      0.00        58\n",
      "             hospitals       0.00      0.00      0.00        86\n",
      "                 shops       0.00      0.00      0.00        39\n",
      "           aid_centers       0.00      0.00      0.00       129\n",
      "  other_infrastructure       0.46      0.02      0.03       378\n",
      "       weather_related       0.86      0.67      0.75      2430\n",
      "                floods       0.90      0.39      0.55       701\n",
      "                 storm       0.76      0.45      0.57       837\n",
      "                  fire       0.50      0.02      0.04        87\n",
      "            earthquake       0.92      0.63      0.75       814\n",
      "                  cold       0.77      0.10      0.18       171\n",
      "         other_weather       0.68      0.03      0.05       475\n",
      "         direct_report       0.73      0.46      0.56      1673\n",
      "\n",
      "           avg / total       0.77      0.54      0.59     27417\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeffsan/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jeffsan/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" LR on Test \"\"\"\n",
    "show_report(pipeline, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "               related       0.99      1.00      0.99     13334\n",
      "               request       1.00      0.92      0.96      2980\n",
      "                 offer       1.00      0.68      0.81        82\n",
      "           aid_related       1.00      0.97      0.98      7277\n",
      "          medical_help       1.00      0.84      0.91      1391\n",
      "      medical_products       1.00      0.84      0.91       906\n",
      "     search_and_rescue       1.00      0.76      0.86       499\n",
      "              security       1.00      0.74      0.85       324\n",
      "              military       1.00      0.88      0.93       593\n",
      "           child_alone       0.00      0.00      0.00         0\n",
      "                 water       1.00      0.93      0.96      1155\n",
      "                  food       1.00      0.94      0.97      1949\n",
      "               shelter       1.00      0.90      0.95      1510\n",
      "              clothing       1.00      0.86      0.93       283\n",
      "                 money       1.00      0.81      0.89       382\n",
      "        missing_people       1.00      0.74      0.85       194\n",
      "              refugees       1.00      0.78      0.88       580\n",
      "                 death       1.00      0.87      0.93       804\n",
      "             other_aid       1.00      0.82      0.90      2284\n",
      "infrastructure_related       1.00      0.78      0.87      1129\n",
      "             transport       1.00      0.80      0.89       801\n",
      "             buildings       1.00      0.86      0.93       863\n",
      "           electricity       1.00      0.84      0.91       359\n",
      "                 tools       1.00      0.77      0.87       101\n",
      "             hospitals       1.00      0.74      0.85       197\n",
      "                 shops       1.00      0.75      0.86        81\n",
      "           aid_centers       1.00      0.70      0.82       180\n",
      "  other_infrastructure       1.00      0.77      0.87       773\n",
      "       weather_related       1.00      0.96      0.98      4856\n",
      "                floods       1.00      0.89      0.94      1448\n",
      "                 storm       1.00      0.94      0.97      1603\n",
      "                  fire       1.00      0.81      0.89       195\n",
      "            earthquake       0.99      0.97      0.98      1638\n",
      "                  cold       1.00      0.83      0.91       357\n",
      "         other_weather       1.00      0.80      0.89       901\n",
      "         direct_report       1.00      0.91      0.95      3391\n",
      "\n",
      "           avg / total       1.00      0.92      0.96     55400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeffsan/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jeffsan/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" RF on Train \"\"\"\n",
    "show_report(pipeline, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "               related       0.85      0.92      0.88      6542\n",
      "               request       0.80      0.46      0.58      1484\n",
      "                 offer       0.00      0.00      0.00        36\n",
      "           aid_related       0.75      0.60      0.67      3564\n",
      "          medical_help       0.56      0.10      0.17       690\n",
      "      medical_products       0.75      0.08      0.15       405\n",
      "     search_and_rescue       0.65      0.14      0.23       225\n",
      "              security       0.12      0.01      0.01       147\n",
      "              military       0.61      0.11      0.19       266\n",
      "           child_alone       0.00      0.00      0.00         0\n",
      "                 water       0.80      0.36      0.50       514\n",
      "                  food       0.85      0.39      0.53       968\n",
      "               shelter       0.85      0.31      0.46       798\n",
      "              clothing       0.85      0.19      0.31       121\n",
      "                 money       0.73      0.04      0.07       221\n",
      "        missing_people       0.67      0.02      0.04       104\n",
      "              refugees       0.67      0.04      0.08       294\n",
      "                 death       0.86      0.13      0.22       388\n",
      "             other_aid       0.46      0.04      0.08      1157\n",
      "infrastructure_related       0.31      0.01      0.01       576\n",
      "             transport       0.78      0.10      0.17       398\n",
      "             buildings       0.75      0.11      0.20       468\n",
      "           electricity       0.64      0.05      0.10       173\n",
      "                 tools       0.00      0.00      0.00        58\n",
      "             hospitals       0.00      0.00      0.00        86\n",
      "                 shops       0.00      0.00      0.00        39\n",
      "           aid_centers       0.00      0.00      0.00       129\n",
      "  other_infrastructure       0.00      0.00      0.00       378\n",
      "       weather_related       0.83      0.62      0.71      2430\n",
      "                floods       0.91      0.37      0.53       701\n",
      "                 storm       0.72      0.34      0.46       837\n",
      "                  fire       1.00      0.03      0.07        87\n",
      "            earthquake       0.90      0.72      0.80       814\n",
      "                  cold       0.93      0.08      0.14       171\n",
      "         other_weather       0.58      0.04      0.08       475\n",
      "         direct_report       0.75      0.35      0.48      1673\n",
      "\n",
      "           avg / total       0.75      0.49      0.54     27417\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeffsan/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jeffsan/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" RF on Test \"\"\"\n",
    "show_report(pipeline, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "               related       0.99      1.00      0.99     13334\n",
      "               request       1.00      0.92      0.96      2980\n",
      "                 offer       1.00      0.67      0.80        82\n",
      "           aid_related       1.00      0.96      0.98      7277\n",
      "          medical_help       1.00      0.83      0.91      1391\n",
      "      medical_products       1.00      0.81      0.89       906\n",
      "     search_and_rescue       1.00      0.73      0.84       499\n",
      "              security       1.00      0.71      0.83       324\n",
      "              military       1.00      0.81      0.90       593\n",
      "           child_alone       0.00      0.00      0.00         0\n",
      "                 water       1.00      0.91      0.95      1155\n",
      "                  food       1.00      0.92      0.96      1949\n",
      "               shelter       1.00      0.87      0.93      1510\n",
      "              clothing       1.00      0.79      0.88       283\n",
      "                 money       1.00      0.79      0.88       382\n",
      "        missing_people       1.00      0.71      0.83       194\n",
      "              refugees       1.00      0.74      0.85       580\n",
      "                 death       1.00      0.84      0.91       804\n",
      "             other_aid       1.00      0.83      0.90      2284\n",
      "infrastructure_related       1.00      0.77      0.87      1129\n",
      "             transport       1.00      0.78      0.87       801\n",
      "             buildings       1.00      0.83      0.91       863\n",
      "           electricity       1.00      0.77      0.87       359\n",
      "                 tools       1.00      0.76      0.87       101\n",
      "             hospitals       1.00      0.72      0.83       197\n",
      "                 shops       1.00      0.75      0.86        81\n",
      "           aid_centers       1.00      0.71      0.83       180\n",
      "  other_infrastructure       1.00      0.75      0.86       773\n",
      "       weather_related       1.00      0.96      0.98      4856\n",
      "                floods       1.00      0.86      0.93      1448\n",
      "                 storm       1.00      0.92      0.96      1603\n",
      "                  fire       1.00      0.77      0.87       195\n",
      "            earthquake       1.00      0.95      0.97      1638\n",
      "                  cold       1.00      0.79      0.88       357\n",
      "         other_weather       1.00      0.77      0.87       901\n",
      "         direct_report       1.00      0.91      0.95      3391\n",
      "\n",
      "           avg / total       1.00      0.91      0.95     55400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeffsan/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jeffsan/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" RF on Train with hashingvec \"\"\"\n",
    "show_report(pipeline, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "               related       0.83      0.93      0.88      6542\n",
      "               request       0.83      0.39      0.53      1484\n",
      "                 offer       0.00      0.00      0.00        36\n",
      "           aid_related       0.76      0.46      0.58      3564\n",
      "          medical_help       0.63      0.03      0.07       690\n",
      "      medical_products       0.88      0.04      0.07       405\n",
      "     search_and_rescue       0.00      0.00      0.00       225\n",
      "              security       0.00      0.00      0.00       147\n",
      "              military       0.67      0.02      0.03       266\n",
      "           child_alone       0.00      0.00      0.00         0\n",
      "                 water       0.85      0.13      0.23       514\n",
      "                  food       0.89      0.26      0.40       968\n",
      "               shelter       0.85      0.08      0.14       798\n",
      "              clothing       0.75      0.05      0.09       121\n",
      "                 money       0.83      0.02      0.04       221\n",
      "        missing_people       0.00      0.00      0.00       104\n",
      "              refugees       0.00      0.00      0.00       294\n",
      "                 death       1.00      0.05      0.10       388\n",
      "             other_aid       0.55      0.04      0.07      1157\n",
      "infrastructure_related       0.00      0.00      0.00       576\n",
      "             transport       0.71      0.01      0.02       398\n",
      "             buildings       0.72      0.03      0.05       468\n",
      "           electricity       0.00      0.00      0.00       173\n",
      "                 tools       0.00      0.00      0.00        58\n",
      "             hospitals       0.00      0.00      0.00        86\n",
      "                 shops       0.00      0.00      0.00        39\n",
      "           aid_centers       0.00      0.00      0.00       129\n",
      "  other_infrastructure       0.00      0.00      0.00       378\n",
      "       weather_related       0.84      0.43      0.57      2430\n",
      "                floods       0.88      0.07      0.13       701\n",
      "                 storm       0.73      0.16      0.26       837\n",
      "                  fire       0.00      0.00      0.00        87\n",
      "            earthquake       0.89      0.49      0.63       814\n",
      "                  cold       1.00      0.01      0.02       171\n",
      "         other_weather       1.00      0.00      0.01       475\n",
      "         direct_report       0.76      0.28      0.41      1673\n",
      "\n",
      "           avg / total       0.74      0.40      0.45     27417\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeffsan/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jeffsan/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" RF on Test with hasingvec \"\"\"\n",
    "show_report(pipeline, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf': MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "             oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "            n_jobs=-1),\n",
       " 'clf__estimator': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "             oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       " 'clf__estimator__bootstrap': True,\n",
       " 'clf__estimator__class_weight': None,\n",
       " 'clf__estimator__criterion': 'gini',\n",
       " 'clf__estimator__max_depth': None,\n",
       " 'clf__estimator__max_features': 'auto',\n",
       " 'clf__estimator__max_leaf_nodes': None,\n",
       " 'clf__estimator__min_impurity_decrease': 0.0,\n",
       " 'clf__estimator__min_impurity_split': None,\n",
       " 'clf__estimator__min_samples_leaf': 1,\n",
       " 'clf__estimator__min_samples_split': 2,\n",
       " 'clf__estimator__min_weight_fraction_leaf': 0.0,\n",
       " 'clf__estimator__n_estimators': 10,\n",
       " 'clf__estimator__n_jobs': 1,\n",
       " 'clf__estimator__oob_score': False,\n",
       " 'clf__estimator__random_state': 42,\n",
       " 'clf__estimator__verbose': 0,\n",
       " 'clf__estimator__warm_start': False,\n",
       " 'clf__n_jobs': -1,\n",
       " 'features': FeatureUnion(n_jobs=1,\n",
       "        transformer_list=[('msg_pipeline', Pipeline(memory=None,\n",
       "      steps=[('msg_selector', FunctionTransformer(accept_sparse=False,\n",
       "           func=<function <lambda> at 0x1364bb510>, inv_kw_args=None,\n",
       "           inverse_func=None, kw_args=None, pass_y='deprecated',\n",
       "           validate=False)), ('vect', Cou...gs=None,\n",
       "           inverse_func=None, kw_args=None, pass_y='deprecated',\n",
       "           validate=False))],\n",
       "        transformer_weights=None),\n",
       " 'features__genre_pipeline': FunctionTransformer(accept_sparse=False,\n",
       "           func=<function <lambda> at 0x1364bb378>, inv_kw_args=None,\n",
       "           inverse_func=None, kw_args=None, pass_y='deprecated',\n",
       "           validate=False),\n",
       " 'features__genre_pipeline__accept_sparse': False,\n",
       " 'features__genre_pipeline__func': <function __main__.<lambda>(x)>,\n",
       " 'features__genre_pipeline__inv_kw_args': None,\n",
       " 'features__genre_pipeline__inverse_func': None,\n",
       " 'features__genre_pipeline__kw_args': None,\n",
       " 'features__genre_pipeline__pass_y': 'deprecated',\n",
       " 'features__genre_pipeline__validate': False,\n",
       " 'features__msg_pipeline': Pipeline(memory=None,\n",
       "      steps=[('msg_selector', FunctionTransformer(accept_sparse=False,\n",
       "           func=<function <lambda> at 0x1364bb510>, inv_kw_args=None,\n",
       "           inverse_func=None, kw_args=None, pass_y='deprecated',\n",
       "           validate=False)), ('vect', CountVectorizer(analyzer='word', binary=False, decode_error='stri...y=None)), ('tfidf', TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True))]),\n",
       " 'features__msg_pipeline__memory': None,\n",
       " 'features__msg_pipeline__msg_selector': FunctionTransformer(accept_sparse=False,\n",
       "           func=<function <lambda> at 0x1364bb510>, inv_kw_args=None,\n",
       "           inverse_func=None, kw_args=None, pass_y='deprecated',\n",
       "           validate=False),\n",
       " 'features__msg_pipeline__msg_selector__accept_sparse': False,\n",
       " 'features__msg_pipeline__msg_selector__func': <function __main__.<lambda>(x)>,\n",
       " 'features__msg_pipeline__msg_selector__inv_kw_args': None,\n",
       " 'features__msg_pipeline__msg_selector__inverse_func': None,\n",
       " 'features__msg_pipeline__msg_selector__kw_args': None,\n",
       " 'features__msg_pipeline__msg_selector__pass_y': 'deprecated',\n",
       " 'features__msg_pipeline__msg_selector__validate': False,\n",
       " 'features__msg_pipeline__steps': [('msg_selector',\n",
       "   FunctionTransformer(accept_sparse=False,\n",
       "             func=<function <lambda> at 0x1364bb510>, inv_kw_args=None,\n",
       "             inverse_func=None, kw_args=None, pass_y='deprecated',\n",
       "             validate=False)),\n",
       "  ('vect',\n",
       "   CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "           dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "           lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "           ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "           strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "           tokenizer=<function tokenize at 0x1364bb2f0>, vocabulary=None)),\n",
       "  ('tfidf',\n",
       "   TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True))],\n",
       " 'features__msg_pipeline__tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True),\n",
       " 'features__msg_pipeline__tfidf__norm': 'l2',\n",
       " 'features__msg_pipeline__tfidf__smooth_idf': True,\n",
       " 'features__msg_pipeline__tfidf__sublinear_tf': False,\n",
       " 'features__msg_pipeline__tfidf__use_idf': True,\n",
       " 'features__msg_pipeline__vect': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "         tokenizer=<function tokenize at 0x1364bb2f0>, vocabulary=None),\n",
       " 'features__msg_pipeline__vect__analyzer': 'word',\n",
       " 'features__msg_pipeline__vect__binary': False,\n",
       " 'features__msg_pipeline__vect__decode_error': 'strict',\n",
       " 'features__msg_pipeline__vect__dtype': numpy.int64,\n",
       " 'features__msg_pipeline__vect__encoding': 'utf-8',\n",
       " 'features__msg_pipeline__vect__input': 'content',\n",
       " 'features__msg_pipeline__vect__lowercase': True,\n",
       " 'features__msg_pipeline__vect__max_df': 1.0,\n",
       " 'features__msg_pipeline__vect__max_features': None,\n",
       " 'features__msg_pipeline__vect__min_df': 1,\n",
       " 'features__msg_pipeline__vect__ngram_range': (1, 1),\n",
       " 'features__msg_pipeline__vect__preprocessor': None,\n",
       " 'features__msg_pipeline__vect__stop_words': None,\n",
       " 'features__msg_pipeline__vect__strip_accents': None,\n",
       " 'features__msg_pipeline__vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'features__msg_pipeline__vect__tokenizer': <function __main__.tokenize(text)>,\n",
       " 'features__msg_pipeline__vect__vocabulary': None,\n",
       " 'features__n_jobs': 1,\n",
       " 'features__transformer_list': [('msg_pipeline', Pipeline(memory=None,\n",
       "        steps=[('msg_selector', FunctionTransformer(accept_sparse=False,\n",
       "             func=<function <lambda> at 0x1364bb510>, inv_kw_args=None,\n",
       "             inverse_func=None, kw_args=None, pass_y='deprecated',\n",
       "             validate=False)), ('vect', CountVectorizer(analyzer='word', binary=False, decode_error='stri...y=None)), ('tfidf', TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True))])),\n",
       "  ('genre_pipeline', FunctionTransformer(accept_sparse=False,\n",
       "             func=<function <lambda> at 0x1364bb378>, inv_kw_args=None,\n",
       "             inverse_func=None, kw_args=None, pass_y='deprecated',\n",
       "             validate=False))],\n",
       " 'features__transformer_weights': None,\n",
       " 'memory': None,\n",
       " 'steps': [('features', FeatureUnion(n_jobs=1,\n",
       "          transformer_list=[('msg_pipeline', Pipeline(memory=None,\n",
       "        steps=[('msg_selector', FunctionTransformer(accept_sparse=False,\n",
       "             func=<function <lambda> at 0x1364bb510>, inv_kw_args=None,\n",
       "             inverse_func=None, kw_args=None, pass_y='deprecated',\n",
       "             validate=False)), ('vect', Cou...gs=None,\n",
       "             inverse_func=None, kw_args=None, pass_y='deprecated',\n",
       "             validate=False))],\n",
       "          transformer_weights=None)),\n",
       "  ('clf',\n",
       "   MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "               max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "               min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "               min_samples_leaf=1, min_samples_split=2,\n",
       "               min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "               oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "              n_jobs=-1))]}"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 96 candidates, totalling 288 fits\n",
      "[CV] features__msg_pipeline__vect__ngram_range=(1, 1), features__transformer_weights={'genre_pipeline': 1, 'msg_pipeline': 1}, clf__estimator__n_estimators=50, features__msg_pipeline__vect__max_features=None \n",
      "[CV] features__msg_pipeline__vect__ngram_range=(1, 1), features__transformer_weights={'genre_pipeline': 1, 'msg_pipeline': 1}, clf__estimator__n_estimators=50, features__msg_pipeline__vect__max_features=None \n",
      "[CV] features__msg_pipeline__vect__ngram_range=(1, 1), features__transformer_weights={'genre_pipeline': 1, 'msg_pipeline': 1}, clf__estimator__n_estimators=50, features__msg_pipeline__vect__max_features=None \n",
      "[CV] features__msg_pipeline__vect__ngram_range=(1, 1), features__transformer_weights={'genre_pipeline': 0.5, 'msg_pipeline': 1}, clf__estimator__n_estimators=50, features__msg_pipeline__vect__max_features=None \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-234-1b1243929498>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Fit the grid search object to the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mgrid_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Get the estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# parameters = {\n",
    "#         'features__msg_pipeline__vect__ngram_range': ((1, 1), (1, 2)),\n",
    "#         'features__msg_pipeline__vect__max_df': (0.5, 0.75, 1.0),\n",
    "#         'features__msg_pipeline__vect__max_features': (None, 500,1000, 5000, 10000),\n",
    "#         'clf__estimator__n_estimators': [25, 50, 100, 200, 500],\n",
    "#         'clf__estimator__min_samples_split': [2, 3, 4, 5, 7, 10, 15],\n",
    "#         'features__transformer_weights': (\n",
    "#             {'msg_pipeline': 1, 'genre_pipeline': 1},\n",
    "#             {'msg_pipeline': 1, 'genre_pipeline': 0.5},\n",
    "#             {'msg_pipeline': 0.5, 'genre_pipeline': 1}\n",
    "#         )\n",
    "#     }\n",
    "\n",
    "parameters = {\n",
    "        'features__msg_pipeline__vect__ngram_range': ((1, 1), (1, 2)),\n",
    "        'features__msg_pipeline__vect__max_features': (None, 500,1000, 5000),\n",
    "        'clf__estimator__n_estimators': [50, 100, 200, 500],\n",
    "        'features__transformer_weights': (\n",
    "            {'msg_pipeline': 1, 'genre_pipeline': 1},\n",
    "            {'msg_pipeline': 1, 'genre_pipeline': 0.5},\n",
    "            {'msg_pipeline': 0.5, 'genre_pipeline': 1}\n",
    "        )\n",
    "    }\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters,scoring='f1_micro', verbose=10, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search object to the training data \n",
    "grid_fit = cv.fit(X_train, y_train)\n",
    "\n",
    "# Get the estimator\n",
    "best_clf = grid_fit.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
